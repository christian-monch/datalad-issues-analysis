{"url": "https://api.github.com/repos/datalad/datalad/issues/2097", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/2097/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/2097/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/2097/events", "html_url": "https://github.com/datalad/datalad/issues/2097", "id": 291300618, "node_id": "MDU6SXNzdWUyOTEzMDA2MTg=", "number": 2097, "title": "DataLad crawl fails on a url with a space", "user": {"login": "overlake333", "id": 28018084, "node_id": "MDQ6VXNlcjI4MDE4MDg0", "avatar_url": "https://avatars.githubusercontent.com/u/28018084?v=4", "gravatar_id": "", "url": "https://api.github.com/users/overlake333", "html_url": "https://github.com/overlake333", "followers_url": "https://api.github.com/users/overlake333/followers", "following_url": "https://api.github.com/users/overlake333/following{/other_user}", "gists_url": "https://api.github.com/users/overlake333/gists{/gist_id}", "starred_url": "https://api.github.com/users/overlake333/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/overlake333/subscriptions", "organizations_url": "https://api.github.com/users/overlake333/orgs", "repos_url": "https://api.github.com/users/overlake333/repos", "events_url": "https://api.github.com/users/overlake333/events{/privacy}", "received_events_url": "https://api.github.com/users/overlake333/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-01-24T17:47:52Z", "updated_at": "2018-02-19T04:02:42Z", "closed_at": "2018-02-19T04:02:42Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "#### What is the problem? \r\n\r\n@yarikoptic gave me an exercise to crawl data given a url link to a website and crawler fails. \r\n\r\n#### What steps will reproduce the problem?\r\n``` shell\r\n(ENV) Taylors-MacBook-Pro:demo taylor$ datalad crawl-init --save --template=simple_with_archives 'url=http://myweb.fsu.edu/bgomez/research.html' 'a_href_match_=.*\\.zip$'\r\n[INFO   ] Creating a pipeline to crawl data files from http://myweb.fsu.edu/bgomez/research.html \r\n[INFO   ] Not adding annex.largefiles=exclude=README* and exclude=LICENSE* to git annex calls because already defined to be (not(mimetype=text/*)) \r\n(ENV) Taylors-MacBook-Pro:demo taylor$ datalad crawl                                                                                    \r\n[INFO   ] Loading pipeline specification from ./.datalad/crawl/crawl.cfg \r\n[INFO   ] Creating a pipeline to crawl data files from http://myweb.fsu.edu/bgomez/research.html \r\n[INFO   ] Not adding annex.largefiles=exclude=README* and exclude=LICENSE* to git annex calls because already defined to be (not(mimetype=text/*)) \r\n[INFO   ] Running pipeline [<function Annexificator.switch_branch.<locals>.switch_branch at 0x10c891b70>, [[<datalad.crawler.nodes.crawl_url.crawl_url object at 0x10c8889b0>, a_href_match(query='.*\\\\.zip$'), <datalad.crawler.nodes.annex.Annexificator object at 0x10a917438>]], <function Annexificator.switch_branch.<locals>.switch_branch at 0x10c891bf8>, [<function Annexificator.merge_branch.<locals>.merge_branch at 0x10c891c80>, [find_files(dirs=False, fail_if_none=True, regex='\\\\.(zip|tgz|tar(\\\\..+)?)$', topdir='.'), <function Annexificator.add_archive_content.<locals>._add_archive_content at 0x10c891d08>]], <function Annexificator.switch_branch.<locals>.switch_branch at 0x10c891d90>, <function Annexificator.merge_branch.<locals>.merge_branch at 0x10c891e18>, <function Annexificator.finalize.<locals>._finalize at 0x10c891ea0>] \r\n[INFO   ] Found branch non-dirty -- nothing was committed \r\n[INFO   ] Checking out an existing branch incoming \r\n[INFO   ] Fetching 'http://myweb.fsu.edu/bgomez/research.html' \r\n[INFO   ] Need to download 1.8 MB from http://myweb.fsu.edu/bgomez/HansfordGomez_APSR_2010.zip. No progress indication will be reported \r\n[INFO   ] Need to download 5.1 MB from http://myweb.fsu.edu/bgomez/Weather_Public_File.zip. No progress indication will be reported \r\n[INFO   ] Need to download 127.3 kB from http://myweb.fsu.edu/bgomez/GomezWilson_2006_JOP_Replication Material.zip. No progress indication will be reported \r\n[WARNING] Caught AnnexBatchCommandError: command 'addurl'\r\nError, annex reported failure for addurl: {'command': 'addurl', 'success': False, 'file': None} [annexrepo.py:add_url_to_file:2042] on trial #1. Sleeping 3.000000 and retrying \r\n[WARNING] Caught AnnexBatchCommandError: command 'addurl'\r\nError, annex reported failure for addurl: {'command': 'addurl', 'success': False, 'file': None} [annexrepo.py:add_url_to_file:2042] on trial #2. Sleeping 9.000000 and retrying \r\n[WARNING] Caught AnnexBatchCommandError: command 'addurl'\r\nError, annex reported failure for addurl: {'command': 'addurl', 'success': False, 'file': None} [annexrepo.py:add_url_to_file:2042] on trial #3. Sleeping 27.000000 and retrying \r\n[WARNING] Caught AnnexBatchCommandError: command 'addurl'\r\nError, annex reported failure for addurl: {'command': 'addurl', 'success': False, 'file': None} [annexrepo.py:add_url_to_file:2042] on trial #4. Sleeping 81.000000 and retrying \r\n[WARNING] Caught AnnexBatchCommandError: command 'addurl'\r\nError, annex reported failure for addurl: {'command': 'addurl', 'success': False, 'file': None} [annexrepo.py:add_url_to_file:2042] on trial #5. Sleeping 243.000000 and retrying \r\n```\r\n#### What version of DataLad are you using (run `datalad --version`)? On what operating system (consider running `datalad plugin wtf`)? \r\nVersion 0.9.1\r\n", "closed_by": {"login": "yarikoptic", "id": 39889, "node_id": "MDQ6VXNlcjM5ODg5", "avatar_url": "https://avatars.githubusercontent.com/u/39889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yarikoptic", "html_url": "https://github.com/yarikoptic", "followers_url": "https://api.github.com/users/yarikoptic/followers", "following_url": "https://api.github.com/users/yarikoptic/following{/other_user}", "gists_url": "https://api.github.com/users/yarikoptic/gists{/gist_id}", "starred_url": "https://api.github.com/users/yarikoptic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yarikoptic/subscriptions", "organizations_url": "https://api.github.com/users/yarikoptic/orgs", "repos_url": "https://api.github.com/users/yarikoptic/repos", "events_url": "https://api.github.com/users/yarikoptic/events{/privacy}", "received_events_url": "https://api.github.com/users/yarikoptic/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/2097/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/2097/timeline", "performed_via_github_app": null}