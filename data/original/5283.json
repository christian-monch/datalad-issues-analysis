{"url": "https://api.github.com/repos/datalad/datalad/issues/5283", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/5283/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/5283/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/5283/events", "html_url": "https://github.com/datalad/datalad/issues/5283", "id": 780559832, "node_id": "MDU6SXNzdWU3ODA1NTk4MzI=", "number": 5283, "title": "Creating a new subject subdataset in a large superdataset takes a long time", "user": {"login": "Hoda1394", "id": 16392763, "node_id": "MDQ6VXNlcjE2MzkyNzYz", "avatar_url": "https://avatars.githubusercontent.com/u/16392763?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Hoda1394", "html_url": "https://github.com/Hoda1394", "followers_url": "https://api.github.com/users/Hoda1394/followers", "following_url": "https://api.github.com/users/Hoda1394/following{/other_user}", "gists_url": "https://api.github.com/users/Hoda1394/gists{/gist_id}", "starred_url": "https://api.github.com/users/Hoda1394/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Hoda1394/subscriptions", "organizations_url": "https://api.github.com/users/Hoda1394/orgs", "repos_url": "https://api.github.com/users/Hoda1394/repos", "events_url": "https://api.github.com/users/Hoda1394/events{/privacy}", "received_events_url": "https://api.github.com/users/Hoda1394/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 289240596, "node_id": "MDU6TGFiZWwyODkyNDA1OTY=", "url": "https://api.github.com/repos/datalad/datalad/labels/performance", "name": "performance", "color": "f4b2d8", "default": false, "description": "Improve performance of an existing feature"}, {"id": 390153891, "node_id": "MDU6TGFiZWwzOTAxNTM4OTE=", "url": "https://api.github.com/repos/datalad/datalad/labels/UX", "name": "UX", "color": "0052cc", "default": false, "description": "user experience"}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2021-01-06T13:40:25Z", "updated_at": "2021-07-16T18:05:16Z", "closed_at": null, "author_association": "NONE", "active_lock_reason": null, "body": "We are using `datalad` and` datalad ukb` extension to organize and arrange our raw data and projects from UK biobank. we are creating a superdataset with each subject as a subdataset that includes the relevant raw data. so the final superdataset is going to include around 500K subdataset. The issue I am encountering now is that creating a single new subdataset takes a long time (from 1 hr to 3 hrs) that makes the whole process very inefficient. right now, we have around 33K subdataset and it seems that by increasing the number of subjects the new subdataset creation time is increasing.\r\nthis is the first stage of creating the superdataset, so we are populating the subdatasets with already downloaded data and just moving the relevant data into the subdataset folders. Here are the commands I am using in the root of superdataset,\r\n\r\n`datalad create -d subdataset_path`\r\n`datalad ukb-init -d subdataset_path ID fields`\r\n`datalad ukb-update -k key -d subdataset_path`\r\n`datalad save`  or `datalad run` to run all above commands\r\n\r\nukb-update uses a surrogate `ukbfetch `and there is no communication with the ukb server at this point. This whole process is done in the university's HPC system which I mentioned the information below.\r\nI checked the time consumed for each step and the creation time is problematic part which is between 1 to 3 hours for a single subdataset right now (with 33k subdatasets). This time increased gradually as the whole dataset gets larger. My guess is, datalad tries to check some lock files in the large superdataset. \r\nGenerally, I want to know, is there a way to make the process more efficient? and what is the datalad team suggestion for such a project?\r\nFirst, I raised the problem in [NeuroStars](https://neurostars.org/t/creating-a-new-subject-subdataset-in-a-large-superdataset-takes-a-long-time/17869) which I mention here for the reference.\r\n\r\nSome system and software info:\r\ndatalad version: 0.13.3\r\noperating system: linux x86_64\r\ndistribution: CentOS Linux/7.7.1908/Core\r\nfilesystem: utf-8\r\n", "closed_by": null, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/5283/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/5283/timeline", "performed_via_github_app": null}