{"url": "https://api.github.com/repos/datalad/datalad/issues/6", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/6/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/6/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/6/events", "html_url": "https://github.com/datalad/datalad/issues/6", "id": 43927605, "node_id": "MDU6SXNzdWU0MzkyNzYwNQ==", "number": 6, "title": "operation to \"get\" content for files which previously had content fetched", "user": {"login": "yarikoptic", "id": 39889, "node_id": "MDQ6VXNlcjM5ODg5", "avatar_url": "https://avatars.githubusercontent.com/u/39889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yarikoptic", "html_url": "https://github.com/yarikoptic", "followers_url": "https://api.github.com/users/yarikoptic/followers", "following_url": "https://api.github.com/users/yarikoptic/following{/other_user}", "gists_url": "https://api.github.com/users/yarikoptic/gists{/gist_id}", "starred_url": "https://api.github.com/users/yarikoptic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yarikoptic/subscriptions", "organizations_url": "https://api.github.com/users/yarikoptic/orgs", "repos_url": "https://api.github.com/users/yarikoptic/repos", "events_url": "https://api.github.com/users/yarikoptic/events{/privacy}", "received_events_url": "https://api.github.com/users/yarikoptic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 63778592, "node_id": "MDU6TGFiZWw2Mzc3ODU5Mg==", "url": "https://api.github.com/repos/datalad/datalad/labels/enhancement", "name": "enhancement", "color": "0052cc", "default": true, "description": ""}, {"id": 132485920, "node_id": "MDU6TGFiZWwxMzI0ODU5MjA=", "url": "https://api.github.com/repos/datalad/datalad/labels/annex", "name": "annex", "color": "0052cc", "default": false, "description": "Git-annex related issue"}], "state": "closed", "locked": false, "assignee": {"login": "joeyh", "id": 16392, "node_id": "MDQ6VXNlcjE2Mzky", "avatar_url": "https://avatars.githubusercontent.com/u/16392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joeyh", "html_url": "https://github.com/joeyh", "followers_url": "https://api.github.com/users/joeyh/followers", "following_url": "https://api.github.com/users/joeyh/following{/other_user}", "gists_url": "https://api.github.com/users/joeyh/gists{/gist_id}", "starred_url": "https://api.github.com/users/joeyh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joeyh/subscriptions", "organizations_url": "https://api.github.com/users/joeyh/orgs", "repos_url": "https://api.github.com/users/joeyh/repos", "events_url": "https://api.github.com/users/joeyh/events{/privacy}", "received_events_url": "https://api.github.com/users/joeyh/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "joeyh", "id": 16392, "node_id": "MDQ6VXNlcjE2Mzky", "avatar_url": "https://avatars.githubusercontent.com/u/16392?v=4", "gravatar_id": "", "url": "https://api.github.com/users/joeyh", "html_url": "https://github.com/joeyh", "followers_url": "https://api.github.com/users/joeyh/followers", "following_url": "https://api.github.com/users/joeyh/following{/other_user}", "gists_url": "https://api.github.com/users/joeyh/gists{/gist_id}", "starred_url": "https://api.github.com/users/joeyh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/joeyh/subscriptions", "organizations_url": "https://api.github.com/users/joeyh/orgs", "repos_url": "https://api.github.com/users/joeyh/repos", "events_url": "https://api.github.com/users/joeyh/events{/privacy}", "received_events_url": "https://api.github.com/users/joeyh/received_events", "type": "User", "site_admin": false}], "milestone": {"url": "https://api.github.com/repos/datalad/datalad/milestones/17", "html_url": "https://github.com/datalad/datalad/milestone/17", "labels_url": "https://api.github.com/repos/datalad/datalad/milestones/17/labels", "id": 1082708, "node_id": "MDk6TWlsZXN0b25lMTA4MjcwOA==", "number": 17, "title": "Git-annex: Further enhancements", "description": "Continue with enhancements to git-annex following our initial evaluation", "creator": {"login": "yarikoptic", "id": 39889, "node_id": "MDQ6VXNlcjM5ODg5", "avatar_url": "https://avatars.githubusercontent.com/u/39889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yarikoptic", "html_url": "https://github.com/yarikoptic", "followers_url": "https://api.github.com/users/yarikoptic/followers", "following_url": "https://api.github.com/users/yarikoptic/following{/other_user}", "gists_url": "https://api.github.com/users/yarikoptic/gists{/gist_id}", "starred_url": "https://api.github.com/users/yarikoptic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yarikoptic/subscriptions", "organizations_url": "https://api.github.com/users/yarikoptic/orgs", "repos_url": "https://api.github.com/users/yarikoptic/repos", "events_url": "https://api.github.com/users/yarikoptic/events{/privacy}", "received_events_url": "https://api.github.com/users/yarikoptic/received_events", "type": "User", "site_admin": false}, "open_issues": 1, "closed_issues": 8, "state": "closed", "created_at": "2015-04-24T18:36:10Z", "updated_at": "2020-10-06T00:25:35Z", "due_on": null, "closed_at": "2020-02-10T19:57:17Z"}, "comments": 6, "created_at": "2014-09-25T14:49:18Z", "updated_at": "2017-10-08T07:29:36Z", "closed_at": "2017-10-08T07:29:36Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Imagine an annex repository which had some files' content fetched (via 'annex get').  Then modifications to some of those and may be other files were done in the original repository, so if a plain \"git pull\" is performed,  symlinks to new content would get broken and would require manual \"git annex get\" on those files which previously were \"get\"ed at some point in the past.  AFAIK (and from our discussion on IRC, cited below, thanks patagonicus and scalability-junk for discussion) there is no way currently to achieve that without additional script on top in two possible ways:\n1. collecting list of files with local content before \"pull\" and then \"get\"ing them after\n2. retrospection of git/git-annex history for each file without content either it was previously obtained and its content key not dropped later on explicitly.\n\nFWIW -- here is a protocol of IRC session\n\n```\n10:05   yoh: is there a way to 'upgrade' the content which was 'got' already?  e.g. I have some files which got their \n             content delivered to local annex.  then I want to 'git pull' + 'git annex get \n             those_files_for_which_I_had_content'\n10:07   patagonicus: yoh: Probably git annex merge, if pull already got all the branches it needs. No need to do an \n                     extra get, if the data was already copy --to the repo (merge will update your master branch so \n                     that the new file's symlinks appear and the link target will already be there)\n10:08   warp: just do git annex sync?\n10:09   scalability-junk: yeah not sure why someone would manually git pull and push with git annex sync.\n10:09   bremner: sync either gets all content or none\n10:09   scalability-junk: bremner: nope it gets all metadata aka branches and git stuff\n10:09   scalability-junk: content is only synced with git annex sync --content\n10:09   bremner: yes, and then it syncs all content, like I just said\n10:09   scalability-junk: and even then it's not all content, but the content which is preferrer or has not \n                          enough duplicates\n10:10   patagonicus: bremner: No, it's based on preferred content\n10:10   scalability-junk: *preferred\n10:10   bremner: ok, fine. It _still_ doesn't answer yoh's question.\n10:10   patagonicus: But sync does push/pull all branches, so if you want to only sync some. And if you want \n                     to rewrite history you'll probably have to fetch/push --force and do some resets.\n10:11   scalability-junk: rewriting history is a pain\n10:11   yoh: keep also in mind that sync tries to be bidirectional -- I want a clean one-way.\n10:13   scalability-junk: Wasn't said. Alright so yeah git merge probably\n10:18   yoh: checked -- nope -- merge didn't get it and there is no --content for it\n10:19   patagonicus: yoh: Are the symlinks there? And you already pushed that file with git annex copy --to \n                     from a different repo?\n10:19   yoh: I am just trying with two local repos I made for testing... there is no need to copy --to\n10:20   patagonicus: Eh \u2026 then how was the content \"'got' already\"?\n10:20   yoh: ok - 1 sec\n10:23   yoh: eh -- history a bit messy to share... s215bLgyFs\n10:23   yoh: http://slexy.org/view/s215bLgyFs\n10:23   yoh: so this way ;)  after initial clone I 'get' some interesting file.  then if they get modified \n             in origin, I would like to \"update\" them locally as well, but only them\n10:24   yoh: merge itself doesn't even pull... may be I should fetch before and then merge,... let's see\n10:24   patagonicus: Yeah, merge does not do any fetch/pull/push. It just uses the synced/* branches that \n                     are available to update master and git-annex\n10:25   patagonicus: You have no line that would transfer the \"123\" content from d1 to d2, so it's not there.\n10:26   patagonicus: You'll have to run a git annex get afterwards. Or add d2 as a remote to d1 and run git \n                     annex copy --to=d2 at any time.\n10:26   yoh: I understand that... and that is what I would like to achieve -- that some command does that \n             content transfer for those files which had local content before\n10:26   patagonicus: So, basically git annex sync --content without pushing to the remote?\n10:26   yoh: sync  would sync/get all the datafiles\n10:27   yoh: I would like only those present on client already (server shouldn't be aware of the client, so \n             no copy --to)\n10:28   patagonicus: What do you mean with present? Based on the file names or on the content? Because in \n                     your example you have 1 file but two contents (so two different keys in annex' storage. \n                     One content will be present, one (the 123 one) will not).\n10:29   yoh: on the file names\n10:30   patagonicus: Oh. That's going to be complicated, I think. So if there's two files, A and B, and the \n                     client has the content of A and both A and B get changed on the server, only the new \n                     content for A should be made available on the client?\n10:30   yoh: yes\n10:31   yoh: I guess could also be done via retrospection in git/git-annex\n10:33   patagonicus: There's no such feature built into annex at the moment (and I'm not sure if it ever \n                     will be added). Basically what you want to do is: run git annex find (which will list \n                     all files currently in the repo, probably with --print0), run git annex merge to update \n                     master, the run git annex get with the result of the find you previously did. That \n                     wouldn't catch file renaming, but for the basic case\n10:34   patagonicus: it should work. Needs N*M space, though, where N is the number of files in the local \n                     repo and M is the average file name length.\n10:34   patagonicus: I think git annex find --print0 >here && git annex fetch -a && git annex merge && xargs \n                     -0 git annex get <here or something like that should work.\n10:35   patagonicus: Will break if there's ever a merge in which file content was changed that is done \n                     without the find/get pair.\n10:35   yoh: yeap, something like that\n10:36   yoh: because of such corner-cases I think it might be better to do it (optionally?) via full \n             retrospection -- if each file without content ever had content before and was not explicitly \n             dropped\n10:37   patagonicus: Then the runtime would depend on the number of commits on master (times the number of files).\n10:37   patagonicus: Should be doable with a bit of scripting, though.\n10:38   patagonicus: The \"explicetly\" dropped would be harder. Basically you could only find out if any of \n                     the previous versions of a file is still in the local repo. However, if you keep \n                     running git annex unused && git annex dropunused all those would never be in the local \n                     repo.\n10:39   yoh: patagonicus: yes, I know.  But such full retrospection could then be optional for explicit run \n             and/or called if manual operation was detected... may be there could even be some record of a \n             last state when things were \"in order\" to start from that point\n```\n", "closed_by": {"login": "mih", "id": 136479, "node_id": "MDQ6VXNlcjEzNjQ3OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/136479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mih", "html_url": "https://github.com/mih", "followers_url": "https://api.github.com/users/mih/followers", "following_url": "https://api.github.com/users/mih/following{/other_user}", "gists_url": "https://api.github.com/users/mih/gists{/gist_id}", "starred_url": "https://api.github.com/users/mih/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mih/subscriptions", "organizations_url": "https://api.github.com/users/mih/orgs", "repos_url": "https://api.github.com/users/mih/repos", "events_url": "https://api.github.com/users/mih/events{/privacy}", "received_events_url": "https://api.github.com/users/mih/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/6/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/6/timeline", "performed_via_github_app": null}