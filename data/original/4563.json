{"url": "https://api.github.com/repos/datalad/datalad/issues/4563", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/4563/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/4563/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/4563/events", "html_url": "https://github.com/datalad/datalad/issues/4563", "id": 622844424, "node_id": "MDU6SXNzdWU2MjI4NDQ0MjQ=", "number": 4563, "title": "ORA performance", "user": {"login": "bpoldrack", "id": 10498301, "node_id": "MDQ6VXNlcjEwNDk4MzAx", "avatar_url": "https://avatars.githubusercontent.com/u/10498301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bpoldrack", "html_url": "https://github.com/bpoldrack", "followers_url": "https://api.github.com/users/bpoldrack/followers", "following_url": "https://api.github.com/users/bpoldrack/following{/other_user}", "gists_url": "https://api.github.com/users/bpoldrack/gists{/gist_id}", "starred_url": "https://api.github.com/users/bpoldrack/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bpoldrack/subscriptions", "organizations_url": "https://api.github.com/users/bpoldrack/orgs", "repos_url": "https://api.github.com/users/bpoldrack/repos", "events_url": "https://api.github.com/users/bpoldrack/events{/privacy}", "received_events_url": "https://api.github.com/users/bpoldrack/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 2971010147, "node_id": "MDU6TGFiZWwyOTcxMDEwMTQ3", "url": "https://api.github.com/repos/datalad/datalad/labels/RIA/ORA", "name": "RIA/ORA", "color": "E8F2DF", "default": false, "description": "Issues related to RIA-based workflows and related components"}], "state": "open", "locked": false, "assignee": {"login": "bpoldrack", "id": 10498301, "node_id": "MDQ6VXNlcjEwNDk4MzAx", "avatar_url": "https://avatars.githubusercontent.com/u/10498301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bpoldrack", "html_url": "https://github.com/bpoldrack", "followers_url": "https://api.github.com/users/bpoldrack/followers", "following_url": "https://api.github.com/users/bpoldrack/following{/other_user}", "gists_url": "https://api.github.com/users/bpoldrack/gists{/gist_id}", "starred_url": "https://api.github.com/users/bpoldrack/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bpoldrack/subscriptions", "organizations_url": "https://api.github.com/users/bpoldrack/orgs", "repos_url": "https://api.github.com/users/bpoldrack/repos", "events_url": "https://api.github.com/users/bpoldrack/events{/privacy}", "received_events_url": "https://api.github.com/users/bpoldrack/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bpoldrack", "id": 10498301, "node_id": "MDQ6VXNlcjEwNDk4MzAx", "avatar_url": "https://avatars.githubusercontent.com/u/10498301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bpoldrack", "html_url": "https://github.com/bpoldrack", "followers_url": "https://api.github.com/users/bpoldrack/followers", "following_url": "https://api.github.com/users/bpoldrack/following{/other_user}", "gists_url": "https://api.github.com/users/bpoldrack/gists{/gist_id}", "starred_url": "https://api.github.com/users/bpoldrack/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bpoldrack/subscriptions", "organizations_url": "https://api.github.com/users/bpoldrack/orgs", "repos_url": "https://api.github.com/users/bpoldrack/repos", "events_url": "https://api.github.com/users/bpoldrack/events{/privacy}", "received_events_url": "https://api.github.com/users/bpoldrack/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2020-05-21T23:11:42Z", "updated_at": "2021-05-17T11:50:55Z", "closed_at": null, "author_association": "MEMBER", "active_lock_reason": null, "body": "@mih reported super slow transfer speed (~5MB/s) when using the ORA special remote to push data, not only via SSH but even on local filesystem when pushing lots of small files. Furthermore the numbers suggested a massive per-file overhead. So, I'm trying to reproduce and track the issue before continuing work on that special remote.\r\n\r\nDataset with 100k files (1.2 GB), containing only the counter as their content. Runtimes we see should therefore be essentially the overhead only.\r\nComparing `datalad push` to `git annex copy` first to get an idea of the difference, since anything that doesn't show up in a `git annex copy` call is not caused by ORA.\r\nRemote `store` is a RIA store on local FS and `store-storage` is the ORA remote.\r\n\r\n```\r\n(datalad-dev) ben@tree in /tmp/100k-files on git:master\r\n\u2771 time datalad push --to store\r\ncopy(ok): 1 (file) [to store-storage...]                                                                                                                                                                                        \r\ncopy(ok): 10 (file) [to store-storage...]                                                                                                                                                                                       \r\ncopy(ok): 100 (file) [to store-storage...]                                                                                                                                                                                      \r\ncopy(ok): 1000 (file) [to store-storage...]                                                                                                                                                                                     \r\ncopy(ok): 10000 (file) [to store-storage...]                                                                                                                                                                                    \r\ncopy(ok): 10001 (file) [to store-storage...]                                                                                                                                                                                    \r\ncopy(ok): 10002 (file) [to store-storage...]                                                                                                                                                                                    \r\ncopy(ok): 10003 (file) [to store-storage...]                                                                                                                                                                                    \r\ncopy(ok): 10004 (file) [to store-storage...]                                                                                                                                                                                    \r\ncopy(ok): 10005 (file) [to store-storage...]                                                                                                                                                                                    \r\n  [99989 similar messages have been suppressed]                                                                                                                                                                                 \r\npublish(ok): . (dataset) [refs/heads/master->store:refs/heads/master [new branch]]                                                                                                                                              \r\npublish(ok): . (dataset) [refs/heads/git-annex->store:refs/heads/git-annex [new branch]]                                                                                                                                        \r\ndatalad push --to store  445.34s user 114.71s system 113% cpu 8:14.90 total            \r\n```                                      \r\n\r\n```\r\ngit annex copy . --to store-storage  \r\n...\r\n280.97s user 87.55s system 109% cpu  5:35.11 total\r\n```\r\n\r\nNow do a minimal mimicking of what the special remote has to do, to get a lower bound of what we can achieve:\r\n\r\n```\r\nfor i in .git/annex/objects/*/*/*/*; do mkdir -p /tmp/localstore/target/$i; cp $i /tmp/localstore/target/$i/; done;\r\n127.13s user 52.10s system 99% cpu 2:59.42 total\r\n```\r\n\r\nAnother run of `git-annex-copy` as above, but this time `git-annex-remote-ora` executable was changed to run via `cProfile.run`. Here's the output:\r\n\r\n![output](https://user-images.githubusercontent.com/10498301/82693632-29c92e80-9c62-11ea-898f-6870597336ce.png)\r\n\r\nHere is what the communication with annex looks like during the profiled run:\r\n\r\n```\r\ncopy 99999.txt [2020-05-22 18:44:38.483375051] git-annex-remote-ora[1] <-- CHECKPRESENT MD5E-s6--0f60a11b9802921adc60b9a4fa6e67de.txt\r\n[2020-05-22 18:44:38.483492161] git-annex-remote-ora[1] --> DIRHASH MD5E-s6--0f60a11b9802921adc60b9a4fa6e67de.txt\r\n[2020-05-22 18:44:38.483550901] git-annex-remote-ora[1] <-- VALUE x0/Fj/\r\n[2020-05-22 18:44:38.483779637] git-annex-remote-ora[1] --> CHECKPRESENT-FAILURE MD5E-s6--0f60a11b9802921adc60b9a4fa6e67de.txt\r\n(to newstore-storage...) \r\n[2020-05-22 18:44:38.485259953] git-annex-remote-ora[1] <-- TRANSFER STORE MD5E-s6--0f60a11b9802921adc60b9a4fa6e67de.txt .git/annex/objects/x0/Fj/MD5E-s6--0f60a11b9802921adc60b9a4fa6e67de.txt/MD5E-s6--0f60a11b9802921adc60b9a4fa6e67de.txt\r\n[2020-05-22 18:44:38.485490576] git-annex-remote-ora[1] --> DIRHASH MD5E-s6--0f60a11b9802921adc60b9a4fa6e67de.txt\r\n[2020-05-22 18:44:38.48557544] git-annex-remote-ora[1] <-- VALUE x0/Fj/\r\n[2020-05-22 18:44:38.486155951] git-annex-remote-ora[1] --> TRANSFER-SUCCESS STORE MD5E-s6--0f60a11b9802921adc60b9a4fa6e67de.txt\r\nok\r\n```\r\n\r\nThere are two things we do twice, that we may be able to save: \r\n- Check for the existence of the target file. Twice, because `git-annex-copy` w/o `--fast` will first ask `CHECKPRESENT` and we will do it again during `TRANSFER`, since this would be the file to write to. Not completely clear to me yet, whether we can really avoid that. But: It would be even more expensive if the store already has an archive to check for a given key. So - worth trying to find a solution.\r\n- asking annex for `DIRHASH` (same would be true for `DIRHASHLOWER`, of course). Currently has to happen during `CHECKPRESENT` and `TRANSFER` to figure the correct target path. We could cache results for keys, but that cache could grow significantly when annex-copying lots of keys. Would need to think whether there's a smarter way than just keeping the results \"forever\". Nevertheless: Might be worth considering the amount of time we spend waiting/reading what annex has to tell us.\r\n\r\nOverall, however, I can't currently see how to become much faster with ORA itself. If I'm correct in thinking that those calls should give us pretty much overhead only (1-6 bytes actual payload), then the conclusion from the calls measured above is: we are in the 1-3 microseconds per file range for the overhead (depends on what you compare to).\r\n\r\nEdit: Note also, that the plain `mkdir`/`cp` call (actually lacking an additional `mv`) shows that we could gain a factor 2-3 max. Would be good to know what exactly you observed, @mih! How small were those files, how many and how did you measure? \r\n\r\n                                                                                                   ", "closed_by": null, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/4563/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/4563/timeline", "performed_via_github_app": null}