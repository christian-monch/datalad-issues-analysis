{"url": "https://api.github.com/repos/datalad/datalad/issues/1287", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/1287/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/1287/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/1287/events", "html_url": "https://github.com/datalad/datalad/issues/1287", "id": 207455479, "node_id": "MDU6SXNzdWUyMDc0NTU0Nzk=", "number": 1287, "title": "RF: metadata layout, storage, aggregation, and access procedure", "user": {"login": "mih", "id": 136479, "node_id": "MDQ6VXNlcjEzNjQ3OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/136479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mih", "html_url": "https://github.com/mih", "followers_url": "https://api.github.com/users/mih/followers", "following_url": "https://api.github.com/users/mih/following{/other_user}", "gists_url": "https://api.github.com/users/mih/gists{/gist_id}", "starred_url": "https://api.github.com/users/mih/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mih/subscriptions", "organizations_url": "https://api.github.com/users/mih/orgs", "repos_url": "https://api.github.com/users/mih/repos", "events_url": "https://api.github.com/users/mih/events{/privacy}", "received_events_url": "https://api.github.com/users/mih/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 440544386, "node_id": "MDU6TGFiZWw0NDA1NDQzODY=", "url": "https://api.github.com/repos/datalad/datalad/labels/fix-implemented", "name": "fix-implemented", "color": "0e8a16", "default": false, "description": "A fix is available, but has not been merged or released, yet."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2017-02-14T09:05:18Z", "updated_at": "2017-07-14T15:26:57Z", "closed_at": "2017-07-14T15:26:21Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "This will eventually turn into a PR hat implements the described changes.\r\n\r\n## Major aims\r\n\r\n- change the previous concept so metadata aggregation has minimal impact on the Git history of a dataset, in particular no metadata should be directly committed in a superdataset in order to limit the disaster scope in case of \"sensible\" metadata leakage. This is achieved by switching to annex'ed files as metadata store (for basic dataset metadata this is not the case, see below)\r\n- minimize impact on superdataset performance when subdatasets have huge metadata sets. we need to find a good tradeoff between number of required inodes and granularity of storage (ideally the pieces are relatively stable over time for typical datasets)\r\n- mimimize, and ideally entirely avoid, the need to anyhow alter metadata files from sub(sub(sub))datasets when aggregating upwards. At the same time enable filtering options for metadata aggregation in superdatasets, in particular avoiding the need for heuristics and needless metadata tagging to enable filtering when everything is stored in a single file\r\n- ~~avoid fileformat debate/selection/support for basic dataset metadata by using git annex's own metadata API. This will maintain the concept of *immediate metadata availability* after having obtained no more than the Git repo of a dataset~~ PR #1630 provides a hybrid approach to this. It allows manipulation via a uniform API (gitannex and dataset metadata), but keeps storage of dataset-level metadata in a file in Git\r\n\r\n## Storage concept\r\n\r\n- no conflict with previous scheme, old metadata can be kept for as long as desired by dataset author\r\n- two locations are used\r\n    - `.datalad/metadata/info`: JSON file providing basic properties for all aggregated metadata files in the store (see next). This file is always present, even when no subdatasets exist.\r\n        - **Basic dataset metadata is attached to this file using `git annex metadata`**. We might need to include some info on subdatasets in here too, in order to have useful minimal metadata for subdatasets after \"`git clone`\"\r\n        - Basic dataset metadata of **subdataset** could be aggregated into the **content** of this file in a superdataset\r\n        - this is an annex'ed file: this is a requirement of using git annex metadata, but also completes the detachment of aggregated metadata content from a superdataset.\r\n    - `.datalad/meta/objects`: directory of annex'ed files for all aggregated metadata from subdatasets.\r\n        - filenames could be something like: `<hash>-<categorylabel>`, where `<hash>` is the SHA of the repository the metadata was produced from (or maybe something shorter than the SHA, but with equally low collision probability in this context), and `<categorylabel>` is an identifier for the \"type\" of metadata -- in order to distinguish multiple metadata sets produced from the same dataset state\r\n        - the content of these files *must not* require any change when aggregating/moving an additional level upward, i.e. any superdataset in a hierarchy references the same annex\r\n          file of a subdataset's metadata set, any information required to fully \"resolve\" a subdataset's metadata in a particular superdataset, must be placed into that superdatasets's `.datalad/meta/info` (e.g. \"mount point\" with respect to the hierarchy). In particular, no information about the detailed state of a dataset should be in these files (commit SHAs, volatile info on remote configuration, see e.g. #1437). This means that any restructuring of subdatasets in a superdataset will only require an update of datasets upward in the hierarchy, and will never require a re-aggregation of the downward tree branches.\r\n        - if we are concerned by the potential number of files when aggregating a huge hierarchy, we could use the same object store concept as annex (with intermediate subdirectories).\r\n        - **the filesystem hierarchy of subdatasets is not reflected in this directory**. subdataset relationship will not be encoded in the filenames either, but must be read from `.datalad/meta/info`.\r\n- files with aggregated metadata stay JSON-LD as before\r\n- helpers should become available to facilitate annex metadata based tagging of dataset content based on the metadata sources supported by git annex\r\n    - e.g. tag all \"cardiac trace recordings\" with a corresponding label\r\n    - we need an API to be able to configure this and enable automatic annex metadata update when the dataset changes\r\n\r\n## Procedures on leaf datasets (dataset with actual data)\r\n\r\n- metadata aggregation -- converting data from an arbitrary format into our own (homogenized) JSON-LD\r\n    - also known as \"caching\"\r\n    - the results are annexed per-metadata source files in `.datalad/meta/objects` that are listed in `.datalad/meta/info`\r\n- metadata \"import\" from our cached, homogenized metadata into git annex metadata -- this step must be configurable, and we need to be able re-run automatically it whenever needed (dataset changed); annex has a `annex.genmetadata` config items and also a `post-commit-annex` hook script.\r\n    - attaching (minimal/reasonable) dataset metadata to (not into!) `.datalad/meta/info`\r\n    - tagging individual files based on metadata\r\n- metadata query -- load info in `.datalad/meta/objects` and `.datalad/meta/info` to build a full graph for query\r\n\r\n## Procedures on superdatasets\r\n\r\n- metadata aggregation -- re-annexing unaltered files from subdatasets' `.datalad/meta/objects`, transfer their availability info if possible (for this a `copy` command would be helpful). Any information about the exact state of the subdatasets must go into `.datalad/meta/info` of the superdataset\r\n- metadata query -- identical to leaf dataset procedure\r\n\r\n## [List of ideas and realizations from initial brain storming]\r\n\r\n- there can be multiple native metadata source per dataset\r\n- there is metadata for a dataset as a whole, and for individual files in a dataset\r\n- extraction of metadata from their native formats can be costly -> cache locally\r\n  (somewhere, in some form, not necessarily the same as for aggregation)\r\n- aggregation of metadata in superdatasets must not require availability of an entire\r\n  dataset hierarchy -> store intermediate aggregation levels in datasets\r\n- metadata itself can be heavy -> distinguish between light and heavy meta data and\r\n  use appropriate storage, e.g. put heavy aggregated metadata into annex, while keeping\r\n  light metadata in git. Heavy vs. light is not necessarily equivalent to\r\n  dataset-level vs. file-level\r\n- superdataset authors must be able to filter out undesired metadata on\r\n  aggregate, e.g. disable by metadata source\r\n- annex provides a file/key-based key-value metadata store, but nothing for a dataset\r\n  as a whole, or for any sub-hierarchy within a single repository. However, it could be\r\n  coaxed into it by attaching metadata to files in a shadow hierarchy under .datalad/meta\r\n  (presently done with JSON files already). Files would need to contain the respective\r\n  ID of the component they are describing to yield a unique key in the annex\r\n\r\n  Note, git-annex cannot natively handle meta data for files with content\r\n  directly in git, and also not for submodules (mount points).\r\n\r\n- Using the git annex metadata store could be superior to checking metadata storage files\r\n  into git. we have tools to cut history of the git-annex branch already, while it is harder\r\n  (but not impossible) to achieve the same for a custom solution. Generally, we don't have\r\n  much interest in metadata history (we generate it from actual content), and the less we\r\n  have it impact the filesystem the better\r\n- a related issue is to expose meaningful metadata for metadata-based views in git-annex\r\n  (i.e. all anatomical images only). This could be achieved by generating tags from native\r\n  metadata via a dedicated parser function\r\n\r\nBottom line: I am debating whether to change the storage concept for metadata from custom\r\nfiles with JSON-LD content to JSON-LD metadata values in annex's keystore.", "closed_by": {"login": "mih", "id": 136479, "node_id": "MDQ6VXNlcjEzNjQ3OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/136479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mih", "html_url": "https://github.com/mih", "followers_url": "https://api.github.com/users/mih/followers", "following_url": "https://api.github.com/users/mih/following{/other_user}", "gists_url": "https://api.github.com/users/mih/gists{/gist_id}", "starred_url": "https://api.github.com/users/mih/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mih/subscriptions", "organizations_url": "https://api.github.com/users/mih/orgs", "repos_url": "https://api.github.com/users/mih/repos", "events_url": "https://api.github.com/users/mih/events{/privacy}", "received_events_url": "https://api.github.com/users/mih/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/1287/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/1287/timeline", "performed_via_github_app": null}