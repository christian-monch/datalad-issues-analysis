{"url": "https://api.github.com/repos/datalad/datalad/issues/4395", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/4395/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/4395/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/4395/events", "html_url": "https://github.com/datalad/datalad/issues/4395", "id": 598023245, "node_id": "MDU6SXNzdWU1OTgwMjMyNDU=", "number": 4395, "title": "aggregate_metadata: removes (non)obsolete metadata files", "user": {"login": "yarikoptic", "id": 39889, "node_id": "MDQ6VXNlcjM5ODg5", "avatar_url": "https://avatars.githubusercontent.com/u/39889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yarikoptic", "html_url": "https://github.com/yarikoptic", "followers_url": "https://api.github.com/users/yarikoptic/followers", "following_url": "https://api.github.com/users/yarikoptic/following{/other_user}", "gists_url": "https://api.github.com/users/yarikoptic/gists{/gist_id}", "starred_url": "https://api.github.com/users/yarikoptic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yarikoptic/subscriptions", "organizations_url": "https://api.github.com/users/yarikoptic/orgs", "repos_url": "https://api.github.com/users/yarikoptic/repos", "events_url": "https://api.github.com/users/yarikoptic/events{/privacy}", "received_events_url": "https://api.github.com/users/yarikoptic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 289240596, "node_id": "MDU6TGFiZWwyODkyNDA1OTY=", "url": "https://api.github.com/repos/datalad/datalad/labels/performance", "name": "performance", "color": "f4b2d8", "default": false, "description": "Improve performance of an existing feature"}, {"id": 390153891, "node_id": "MDU6TGFiZWwzOTAxNTM4OTE=", "url": "https://api.github.com/repos/datalad/datalad/labels/UX", "name": "UX", "color": "0052cc", "default": false, "description": "user experience"}, {"id": 1782622781, "node_id": "MDU6TGFiZWwxNzgyNjIyNzgx", "url": "https://api.github.com/repos/datalad/datalad/labels/severity-important", "name": "severity-important", "color": "cc0000", "default": false, "description": "major effect on the usability of a package, without rendering it completely unusable to everyone"}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2020-04-10T18:18:06Z", "updated_at": "2020-04-10T18:35:00Z", "closed_at": null, "author_association": "MEMBER", "active_lock_reason": null, "body": "I was trying to re-enable a test which was disabled in the past claiming (in the comments, not commit message) some metadata incompatibility (see d4cf4d8b4e94da8713b9d84f7bc6e8f29e6ee96f), and while at it tried my staple search query, to just get surprised to see pretty much no results.  As you can see below it boils down to the commit in datasets.datalad.org dataset which removed metadata files claiming them being obsolete.\r\n\r\n<details>\r\n<summary>Example:</summary> \r\n\r\nInstall dataset, and get to the commit which removed \"obsolete\" files:\r\n```shell\r\n$> datalad install /// && cd datasets.datalad.org && git checkout b5e2df5794c1282daed61de6b1fa64df700a7a5f\r\ninstall(ok): /tmp/datasets.datalad.org (dataset)                                                                                                 \r\nNote: switching to 'b5e2df5794c1282daed61de6b1fa64df700a7a5f'.\r\n\r\nYou are in 'detached HEAD' state. You can look around, make experimental\r\n...\r\nHEAD is now at b5e2df5 [DATALAD] Remove obsolete metadata object files\r\n\r\n$> datalad search haxby                                                                                   \r\ndatalad search haxby  97.12s user 42.97s system 108% cpu 2:09.12 total\r\n\r\n$> datalad --version\r\ndatalad 0.12.5.dev24\r\n```\r\n</details>\r\n\r\nin above - `search` using current maint version (0.12.5.dev24) takes WAY too long (97sec), returns without any output/feedback.  While at it `top` shows datalad appearing once in a while at 10% CPU load, but otherwise seems to be awaiting for some IO...\r\n\r\n<details>\r\n<summary>Looking at debug log - it seems spending time assigning those (non existing) metadata object files into the main dataset</summary> \r\n\r\n```shell\r\n[DEBUG  ] Determined class of decorated function: <class 'datalad.local.subdatasets.Subdatasets'> \r\n[DEBUG  ] Resolved dataset for subdataset reporting/modification: /tmp/datasets.datalad.org \r\n[DEBUG  ] Query subdatasets of <Dataset path=/tmp/datasets.datalad.org> \r\n[DEBUG  ] <AnnexRepo path=/tmp/datasets.datalad.org (<class 'datalad.support.annexrepo.AnnexRepo'>)>.get_content_info(...) \r\n[DEBUG  ] Query repo: ['git', 'ls-files', '--stage', '-z', '-d', '-m', '--exclude-standard'] \r\n[DEBUG  ] Done query repo: ['git', 'ls-files', '--stage', '-z', '-d', '-m', '--exclude-standard'] \r\n[DEBUG  ] Done <AnnexRepo path=/tmp/datasets.datalad.org (<class 'datalad.support.annexrepo.AnnexRepo'>)>.get_content_info(...) \r\n[DEBUG  ] Not reporting result (excluded by filter <function get_result_filter.<locals>._fx at 0x7fe93aaa83b0> with arguments {'path': None, 'dataset': <Dataset path=/tmp/datasets.datalad.org>, 'fulfilled': None, 'recursive': True, 'recursion_limit': None, 'contains': PosixPath('/tmp/datasets.datalad.org/.datalad/metadata/objects/31/ds-af94a808f634ec508c87a5162964e2'), 'bottomup': False, 'set_property': None, 'delete_property': None, 'on_failure': 'ignore', 'result_filter': <function is_ok_dataset at 0x7fe93bd18200>} [utils.py:keep_result:610]): {'action': 'subdataset', 'path': '/tmp/datasets.datalad.org/.datalad/metadata/objects/31/ds-af94a808f634ec508c87a5162964e2', 'status': 'impossible', 'message': 'path not contained in any matching subdataset'} \r\n[DEBUG  ] Determined class of decorated function: <class 'datalad.local.subdatasets.Subdatasets'> \r\n[DEBUG  ] Resolved dataset for subdataset reporting/modification: /tmp/datasets.datalad.org \r\n[DEBUG  ] Query subdatasets of <Dataset path=/tmp/datasets.datalad.org> \r\n[DEBUG  ] <AnnexRepo path=/tmp/datasets.datalad.org (<class 'datalad.support.annexrepo.AnnexRepo'>)>.get_content_info(...) \r\n[DEBUG  ] Query repo: ['git', 'ls-files', '--stage', '-z', '-d', '-m', '--exclude-standard'] \r\n[DEBUG  ] Done query repo: ['git', 'ls-files', '--stage', '-z', '-d', '-m', '--exclude-standard'] \r\n[DEBUG  ] Done <AnnexRepo path=/tmp/datasets.datalad.org (<class 'datalad.support.annexrepo.AnnexRepo'>)>.get_content_info(...) \r\n[DEBUG  ] Not reporting result (excluded by filter <function get_result_filter.<locals>._fx at 0x7fe93aaa84d0> with arguments {'path': None, 'dataset': <Dataset path=/tmp/datasets.datalad.org>, 'fulfilled': None, 'recursive': True, 'recursion_limit': None, 'contains': PosixPath('/tmp/datasets.datalad.org/.datalad/metadata/objects/a6/ds-99480ae1070de795c287271f85aee3'), 'bottomup': False, 'set_property': None, 'delete_property': None, 'on_failure': 'ignore', 'result_filter': <function is_ok_dataset at 0x7fe93bd18200>} [utils.py:keep_result:610]): {'action': 'subdataset', 'path': '/tmp/datasets.datalad.org/.datalad/metadata/objects/a6/ds-99480ae1070de795c287271f85aee3', 'status': 'impossible', 'message': 'path not contained in any matching subdataset'} \r\n[DEBUG  ] Determined class of decorated function: <class 'datalad.local.subdatasets.Subdatasets'> \r\n[DEBUG  ] Resolved dataset for subdataset reporting/modification: /tmp/datasets.datalad.org \r\n[DEBUG  ] Query subdatasets of <Dataset path=/tmp/datasets.datalad.org> \r\n[DEBUG  ] <AnnexRepo path=/tmp/datasets.datalad.org (<class 'datalad.support.annexrepo.AnnexRepo'>)>.get_content_info(...) \r\n[DEBUG  ] Query repo: ['git', 'ls-files', '--stage', '-z', '-d', '-m', '--exclude-standard'] \r\n^C[DEBUG  ] Terminating process for ['git', 'ls-files', '--stage', '-z', '-d', '-m', '--exclude-standard'] upon exception: KeyboardInterrupt() [selectors.py:select:415] \r\nERROR: \r\nInterrupted by user while doing magic: KeyboardInterrupt() [selectors.py:select:415]\r\n\r\n$> ls -ld /tmp/datasets.datalad.org/.datalad/metadata/objects/31/ds-af94a808f634ec508c87a5162964e2\r\nls: cannot access '/tmp/datasets.datalad.org/.datalad/metadata/objects/31/ds-af94a808f634ec508c87a5162964e2': No such file or directory\r\n\r\n$> git show --numstat b5e2df5794c1282daed61de6b1fa64df700a7a5f | grep  ds-af94a808f634ec508c87a5162964e2 \r\n0\t168\t.datalad/metadata/objects/31/ds-af94a808f634ec508c87a5162964e2\r\n```\r\n</details>\r\n\r\n<details>\r\n<summary>If I checkout state before removal of \"obsolete\" files, things look and behave much better (checkout takes awhile). It doesn't try to figure out if those absent file belong to some subdataset, just `get`s them and returns search result (cold run with `get` - 13 sec, subsequent 2.5 sec).</summary> \r\n\r\n```shell\r\n$> time datalad search Haxby\r\nsearch(ok): /tmp/datasets.datalad.org/hbnssi (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/labs/gobbini/famface/data (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/labs/haxby (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/labs/haxby/attention (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/labs/haxby/life (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/labs/haxby/raiders (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/openfmri/ds000105 (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/openfmri/ds000233 (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/openfmri/ds000241 (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/openneuro/ds000105 (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/openneuro/ds000233 (dataset)\r\nsearch(ok): /tmp/datasets.datalad.org/openneuro/ds000241 (dataset)\r\naction summary:\r\n  search (ok: 12)\r\ndatalad search Haxby  2.58s user 0.48s system 103% cpu 2.961 total\r\n```\r\n</details>\r\n\r\n<details>\r\n<summary>Interesting fact is that only metadata files were removed, no changes to `aggregate_v1.json`</summary> \r\n\r\n```shell\r\n$> git show --numstat b5e2df5794c1282daed61de6b1fa64df700a7a5f | grep -v objects\r\ncommit b5e2df5794c1282daed61de6b1fa64df700a7a5f\r\nAuthor: Yaroslav Halchenko <debian@onerussian.com>\r\nDate:   Thu Mar 12 17:26:28 2020 -0400\r\n\r\n    [DATALAD] Remove obsolete metadata object files\r\n```\r\n\r\nso - no files listed\r\n</details>\r\n\r\n<details>\r\n<summary>and it is only 2 datasets metadata files left:</summary> \r\n\r\n```shell\r\n$> grep \"objects/\" .datalad/metadata/aggregate_v1.json | sed -e 's,[\",],,g' | while read f; do /bin/ls \".datalad/metadata/$f\" > /dev/null 2>&1 && echo $f ok; done\r\nobjects/da/cn-8d9c7577490ce2d3ef81bccf0c1a7a.xz ok\r\nobjects/da/ds-8d9c7577490ce2d3ef81bccf0c1a7a ok\r\nobjects/61/cn-48667e6e29c6b0a97dc01db751e641.xz ok\r\nobjects/61/ds-48667e6e29c6b0a97dc01db751e641 ok\r\n\r\n$> grep \"objects/\" .datalad/metadata/aggregate_v1.json | sed -e 's,[\",],,g' | while read f; do /bin/ls \".datalad/metadata/$f\" > /dev/null 2>&1 || echo $f nok; done  | nl | tail\r\n  1339\tobjects/87/cn-8860472d72b8631fdd13b189d0b314.xz nok\r\n  1340\tobjects/87/ds-8860472d72b8631fdd13b189d0b314 nok\r\n  1341\tobjects/f0/cn-3bee1f3d11686ff46b205b8686a4ae.xz nok\r\n  1342\tobjects/f0/ds-3bee1f3d11686ff46b205b8686a4ae nok\r\n  1343\tobjects/36/cn-008eea765a7199ca96c3f27244ffe9.xz nok\r\n  1344\tobjects/36/ds-008eea765a7199ca96c3f27244ffe9 nok\r\n  1345\tobjects/84/cn-67d4d07a092ef46cdaa22d9b0e7e00.xz nok\r\n  1346\tobjects/84/ds-67d4d07a092ef46cdaa22d9b0e7e00 nok\r\n  1347\tobjects/de/cn-e40b46f06f81928c6b9eddae1b5a0e.xz nok\r\n  1348\tobjects/de/ds-e40b46f06f81928c6b9eddae1b5a0e nok\r\n\r\n```\r\n</details>\r\n\r\n<details>\r\n<summary>so metadata for everything but one subdataset (and root) was removed, and that dataset is `labs`:\r\n</summary> \r\n\r\n```shell\r\n$> jql .datalad/metadata/aggregate_v1.json| grep -3 48667e6e29c6b0a97dc01db751e641\r\nFailed to detect file type of .datalad/metadata/aggregate_v1.json.\r\n    \"refcommit\": \"313513f66a7d9ab8d3ed6c3e41444237a61c1174\"\r\n  },\r\n  \"labs\": {\r\n    \"content_info\": \"objects/61/cn-48667e6e29c6b0a97dc01db751e641.xz\",\r\n    \"datalad_version\": \"0.10.0.rc5.dev18\",\r\n    \"dataset_info\": \"objects/61/ds-48667e6e29c6b0a97dc01db751e641\",\r\n    \"extractors\": [\r\n      \"datalad_core\",\r\n      \"annex\",\r\n```\r\n</details>\r\n\r\nalthough I do not see any explicit commit adjusting labs around that point\r\n<details>\r\n<summary></summary> \r\n\r\n```shell\r\n607f096 Updated RawDataBIDS which what is updateable (no permission denied or completely removed keys)\r\n927a6ba [DATALAD] Dataset aggregate metadata update\r\nb5e2df5 (HEAD) [DATALAD] Remove obsolete metadata object files\r\n4896a04 adding hcp-openaccess\r\nfdec1ee containers was updated\r\n```\r\n</details>\r\nSince we do not record datalad version used to produce changes (see fresh #4394) -- not yet sure if that could have been due to some older datalad or some new one to blame.\r\n\r\nI think altogether there are multiple issues, which are yet to be troubleshooted separately and filed:\r\n\r\n- [ ] whatever command lead to this was buggy.  most likely -- `aggregate-metadata`. Likely ran with a specific path. (this one severity-important if not critical, thus marking this issue important for now, later - just move label there)\r\n\r\n- [ ] we should report if some (number of them? paths they cover?) metadata objects are not available (at all, or not `get`able) whenever they should be  (UX)\r\n\r\n- [ ] avoid lengthy questioning of the files under the path which we know does not have any subdatasets where they potentially belong. (OPT)", "closed_by": null, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/4395/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/4395/timeline", "performed_via_github_app": null}