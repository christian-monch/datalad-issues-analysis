{"url": "https://api.github.com/repos/datalad/datalad/issues/5048", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/5048/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/5048/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/5048/events", "html_url": "https://github.com/datalad/datalad/pull/5048", "id": 723370193, "node_id": "MDExOlB1bGxSZXF1ZXN0NTA0OTY3NTY1", "number": 5048, "title": "BF: make AnnexRepo.add() raise an IncompleteResultsException if any non-success", "user": {"login": "yarikoptic", "id": 39889, "node_id": "MDQ6VXNlcjM5ODg5", "avatar_url": "https://avatars.githubusercontent.com/u/39889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yarikoptic", "html_url": "https://github.com/yarikoptic", "followers_url": "https://api.github.com/users/yarikoptic/followers", "following_url": "https://api.github.com/users/yarikoptic/following{/other_user}", "gists_url": "https://api.github.com/users/yarikoptic/gists{/gist_id}", "starred_url": "https://api.github.com/users/yarikoptic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yarikoptic/subscriptions", "organizations_url": "https://api.github.com/users/yarikoptic/orgs", "repos_url": "https://api.github.com/users/yarikoptic/repos", "events_url": "https://api.github.com/users/yarikoptic/events{/privacy}", "received_events_url": "https://api.github.com/users/yarikoptic/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 374318336, "node_id": "MDU6TGFiZWwzNzQzMTgzMzY=", "url": "https://api.github.com/repos/datalad/datalad/labels/conference%20agenda%20item", "name": "conference agenda item", "color": "fbca04", "default": false, "description": "Scheduled to be discussed in a developer meeting"}, {"id": 1453907298, "node_id": "MDU6TGFiZWwxNDUzOTA3Mjk4", "url": "https://api.github.com/repos/datalad/datalad/labels/stale-PR-closed-without-merge", "name": "stale-PR-closed-without-merge", "color": "ffffff", "default": false, "description": ""}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2020-10-16T16:39:27Z", "updated_at": "2021-05-25T07:37:54Z", "closed_at": "2021-05-25T07:37:46Z", "author_association": "MEMBER", "active_lock_reason": null, "pull_request": {"url": "https://api.github.com/repos/datalad/datalad/pulls/5048", "html_url": "https://github.com/datalad/datalad/pull/5048", "diff_url": "https://github.com/datalad/datalad/pull/5048.diff", "patch_url": "https://github.com/datalad/datalad/pull/5048.patch"}, "body": "Initial awareness came from troubleshooting on Windows\r\nhttps://github.com/datalad/datalad/issues/5015#issuecomment-709436065\r\n\r\nMajority of .add (as opposed to .add_ generator) invocations are not\r\ntesting/using returned value and GitRepo.add would return only\r\nsuccess-ful results and raise some Exception otherwise.\r\n\r\nSince AnnexRepo.add relies on add_ which is going through --json\r\nmode of git-annex to provide both succeeded and not results,\r\nadd() just returned records with success: False and did not\r\nraise any exception (even if GitAnnex exited with non-0).  That is not\r\n\"in-line\" with GitRepo.add and also leads to us not detecting errors\r\nwhen plain AnnexRepo.add  is used.\r\n\r\nI have not figured out a better/less confusing way than to add additional kwarg\r\nexpect_success to _run_annex_command_json .  Generator versions then would set\r\nit to False, while outside \"procedural\" ones, where not \"manually\" processing\r\nresults (e.g. like .copy_to does), should set it to True for the\r\n\"centralized\" handling.\r\n\r\nI have subsequent similar changes (also introducing matching `_` generator forms) to some other AnnexRepo interfaces (eg `get`, `drop`, ...) which IMHO should be done to unify behavior and avoid \"errors disregard\".  Although some of them should probably go against `maint`, not yet sure if should, or should go against `master`.  First I want to see if any side-effects from `add` \"fixup\".\r\n\r\n<details>\r\n<summary>current version of that further patch</summary> \r\n\r\n```diff\r\ndiff --git a/datalad/distribution/drop.py b/datalad/distribution/drop.py\r\nindex 64a7292c1..03adec72d 100644\r\n--- a/datalad/distribution/drop.py\r\n+++ b/datalad/distribution/drop.py\r\n@@ -94,7 +94,7 @@ def _drop_files(ds, paths, check, noannex_iserror=False, **kwargs):\r\n \r\n     opts = ['--force'] if not check else []\r\n     respath_by_status = {}\r\n-    for res in ds.repo.drop(paths, options=opts):\r\n+    for res in ds.repo.drop_(paths, options=opts):\r\n         res = annexjson2result(\r\n             # annex reports are always about files\r\n             res, ds, type='file', **kwargs)\r\ndiff --git a/datalad/distribution/get.py b/datalad/distribution/get.py\r\nindex 925b61919..60542cbb8 100644\r\n--- a/datalad/distribution/get.py\r\n+++ b/datalad/distribution/get.py\r\n@@ -584,7 +584,9 @@ def _get_targetpaths(ds, content, refds_path, source, jobs):\r\n     for res in ds_repo.get(\r\n             content,\r\n             options=['--from=%s' % source] if source else [],\r\n-            jobs=jobs):\r\n+            jobs=jobs,\r\n+            expect_success=False,\r\n+    ):\r\n         res = annexjson2result(res, ds, type='file', logger=lgr,\r\n                                refds=refds_path)\r\n         success = success_status_map[res['status']]\r\ndiff --git a/datalad/plugin/addurls.py b/datalad/plugin/addurls.py\r\nindex a401171fe..1843370cf 100644\r\n--- a/datalad/plugin/addurls.py\r\n+++ b/datalad/plugin/addurls.py\r\n@@ -25,7 +25,10 @@ from datalad.interface.base import Interface\r\n from datalad.interface.base import build_doc\r\n from datalad.interface.results import annexjson2result, get_status_dict\r\n from datalad.interface.common_opts import nosave_opt\r\n-from datalad.support.exceptions import AnnexBatchCommandError\r\n+from datalad.support.exceptions import (\r\n+    AnnexBatchCommandError,\r\n+    IncompleteResultsError,\r\n+)\r\n from datalad.support.network import get_url_filename\r\n from datalad.support.path import split_ext\r\n from datalad.support.s3 import get_versioned_url\r\n@@ -522,7 +525,7 @@ def add_urls(rows, ifexists=None, options=None):\r\n         try:\r\n             out_json = ds.repo.add_url_to_file(filename, row[\"url\"],\r\n                                                batch=True, options=options)\r\n-        except AnnexBatchCommandError as exc:\r\n+        except (AnnexBatchCommandError, IncompleteResultsError) as exc:\r\n             yield get_status_dict(action=\"addurls\",\r\n                                   ds=ds,\r\n                                   type=\"file\",\r\ndiff --git a/datalad/support/annexrepo.py b/datalad/support/annexrepo.py\r\nindex d978f1671..213ed3e52 100644\r\n--- a/datalad/support/annexrepo.py\r\n+++ b/datalad/support/annexrepo.py\r\n@@ -1300,11 +1300,23 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n             If not specified (None), then\r\n         key : bool, optional\r\n             If provided file value is actually a key\r\n+        expect_success : bool, optional\r\n+            If set to False, no IncompleteResultsError will be raise if any\r\n+            file fails to be obtained\r\n \r\n         Returns\r\n         -------\r\n         files : list of dict\r\n         \"\"\"\r\n+        # TODO:  should we here compare fetch_files against result_list\r\n+        # and vomit an exception of incomplete download????\r\n+        return list(self.get_(\r\n+            files, remote=remote, options=options, jobs=jobs, key=key,\r\n+            expect_success=True))\r\n+\r\n+    def get_(self, files, remote=None, options=None, jobs=None, key=False,\r\n+             expect_success=False):\r\n+        \"\"\"Like `get`, but returns a generator\"\"\"\r\n         options = options[:] if options else []\r\n \r\n         if remote:\r\n@@ -1346,18 +1358,14 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n             kwargs = {'opts': options + ['--key'] + files}\r\n         else:\r\n             kwargs = {'opts': options, 'files': files}\r\n-        results = self._run_annex_command_json(\r\n+        yield from self._run_annex_command_json(\r\n             'get',\r\n             # TODO: eventually make use of --batch mode\r\n             jobs=jobs,\r\n             expected_entries=expected_downloads,\r\n             progress=True,\r\n-            **kwargs\r\n-        )\r\n-        results_list = list(results)\r\n-        # TODO:  should we here compare fetch_files against result_list\r\n-        # and vomit an exception of incomplete download????\r\n-        return results_list\r\n+            expect_success=expect_success,\r\n+            **kwargs)\r\n \r\n     def _get_expected_files(self, files, expr, merge_annex_branches=True):\r\n         \"\"\"Given a list of files, figure out what to be downloaded\r\n@@ -1444,8 +1452,7 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n         return list(self.add_(\r\n             files, git=git, backend=backend, options=options, jobs=jobs,\r\n             git_options=git_options, annex_options=annex_options, update=update,\r\n-            expect_success=True\r\n-        ))\r\n+            expect_success=True))\r\n \r\n     def add_(self, files, git=None, backend=None, options=None, jobs=None,\r\n             git_options=None, annex_options=None, update=False, expect_success=False):\r\n@@ -1534,8 +1541,7 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n                     jobs=jobs,\r\n                     expected_entries=expected_additions,\r\n                     expect_stderr=True,\r\n-                    expect_success=expect_success,\r\n-            )\r\n+                    expect_success=expect_success)\r\n \r\n     @normalize_paths\r\n     def get_file_key(self, files, batch=None):\r\n@@ -1634,6 +1640,8 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n         \"\"\"\r\n         if not files:\r\n             return\r\n+        # TODO: unify in unlock vs unlock_ behavior -- \"higher-level\" interface\r\n+        # should just get full records and process them.\r\n         return [j[\"file\"] for j in\r\n                 self._run_annex_command_json(\"unlock\", files=files)\r\n                 if j[\"success\"]]\r\n@@ -1964,6 +1972,7 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n                 opts=options + [files_opt] + [url],\r\n                 progress=True,\r\n                 expected_entries={file_: None},\r\n+                expect_success=True,\r\n                 **kwargs\r\n             )\r\n             if len(out_json) != 1:\r\n@@ -2093,7 +2102,11 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n           'success' item in each object indicates failure/success per file\r\n           path.\r\n         \"\"\"\r\n+        return list(self.drop_(\r\n+            files, options=options, key=key, jobs=jobs, expect_success=True))\r\n \r\n+    def drop_(self, files, options=None, key=False, jobs=None, expect_success=False):\r\n+        \"\"\"Like `drop_`, but returns a generator\"\"\"\r\n         # annex drop takes either files or options\r\n         # --all, --unused, --key, or --incomplete\r\n         # for now, most simple test; to be replaced by a more general solution\r\n@@ -2112,25 +2125,21 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n             # one at a time\r\n             files = assure_list(files)\r\n             options = options + ['--key']\r\n-            res = [\r\n-                self._run_annex_command_json(\r\n+            for k in files:\r\n+                yield from self._run_annex_command_json(\r\n                     'drop',\r\n                     opts=options + [k],\r\n-                    jobs=jobs)\r\n-                for k in files\r\n-            ]\r\n-            # `normalize_paths` ... magic, useful?\r\n-            if len(files) == 1:\r\n-                return res[0]\r\n-            else:\r\n-                return res\r\n+                    jobs=jobs,\r\n+                    expect_success=expect_success)\r\n         else:\r\n-            return self._run_annex_command_json(\r\n+            yield from self._run_annex_command_json(\r\n                 'drop',\r\n                 opts=options,\r\n                 files=files,\r\n-                jobs=jobs)\r\n+                jobs=jobs,\r\n+                expect_success=expect_success)\r\n \r\n+    # TODO: unify? with add/add_ like for uniform expect_success ? (here just assert)\r\n     def drop_key(self, keys, options=None, batch=False):\r\n         \"\"\"Drops the content of annexed files from this repository referenced by keys\r\n \r\n@@ -2498,6 +2507,8 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n \r\n         options = ['--bytes', '--fast'] if fast else ['--bytes']\r\n \r\n+        # Here we do post-processing and just provide None for records without\r\n+        # 'success', thus not providing expect_success=True\r\n         if not batch:\r\n             json_objects = self._run_annex_command_json(\r\n                 'info', opts=options, files=files, merge_annex_branches=False)\r\n@@ -2550,8 +2561,8 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n         options = ['--bytes', '--fast'] if fast else ['--bytes']\r\n \r\n         json_records = list(self._run_annex_command_json(\r\n-            'info', opts=options, merge_annex_branches=merge_annex_branches)\r\n-        )\r\n+            'info', opts=options, merge_annex_branches=merge_annex_branches,\r\n+            expect_success=True))\r\n         assert(len(json_records) == 1)\r\n \r\n         # TODO: we need to abstract/centralize conversion from annex fields\r\n@@ -2565,7 +2576,6 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n                 else:\r\n                     lgr.debug(\"Size %r reported to be %s, setting to None\", k, size)\r\n                     info[k] = None\r\n-        assert(info.pop('success'))\r\n         assert(info.pop('command') == 'info')\r\n         return info  # just as is for now\r\n \r\n@@ -3160,6 +3170,7 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n             if isinstance(files, str):\r\n                 files = [files]\r\n             # anything else is assumed to be an iterable (e.g. a generator)\r\n+        # ??? expect_success?\r\n         if batch is False:\r\n             for res in self._run_annex_command_json(\r\n                     'metadata', opts=['--json'], files=files):\r\n@@ -3212,11 +3223,13 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n         \"\"\"\r\n         return list(self.set_metadata_(\r\n             files, reset=reset, add=add, init=init,\r\n-            remove=remove, purge=purge, recursive=recursive))\r\n+            remove=remove, purge=purge, recursive=recursive,\r\n+            expect_success=True,\r\n+        ))\r\n \r\n     def set_metadata_(\r\n             self, files, reset=None, add=None, init=None,\r\n-            remove=None, purge=None, recursive=False):\r\n+            remove=None, purge=None, recursive=False, expect_success=False):\r\n         \"\"\"Like set_metadata() but returns a generator\"\"\"\r\n \r\n         def _genspec(expr, d):\r\n@@ -3246,11 +3259,12 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n         # operate on files that were just added.\r\n         self.precommit()\r\n \r\n-        for jsn in self._run_annex_command_json(\r\n+        yield from self._run_annex_command_json(\r\n                 'metadata',\r\n                 args,\r\n-                files=files):\r\n-            yield jsn\r\n+                files=files,\r\n+                expect_success=expect_success,\r\n+        )\r\n \r\n     # TODO: RM DIRECT?  might remain useful to detect submods left in direct mode\r\n     @staticmethod\r\n@@ -3363,6 +3377,7 @@ class AnnexRepo(GitRepo, RepoInterface):\r\n             else:\r\n                 opts.extend(['--include', '*'])\r\n \r\n+        # ??? Do we want expect_success=True here?\r\n         for j in self._run_annex_command_json(cmd, opts=opts, files=files):\r\n             path = self.pathobj.joinpath(ut.PurePosixPath(j['file']))\r\n             rec = info.get(path, None)\r\ndiff --git a/datalad/support/tests/test_annexrepo.py b/datalad/support/tests/test_annexrepo.py\r\nindex 36ce28d0b..3baed1141 100644\r\n--- a/datalad/support/tests/test_annexrepo.py\r\n+++ b/datalad/support/tests/test_annexrepo.py\r\n@@ -432,7 +432,7 @@ def test_AnnexRepo_web_remote(sitepath, siteurl, dst):\r\n     eq_(len(l), 1)\r\n \r\n     # now only 1 copy; drop should fail\r\n-    res = ar.drop(testfile)\r\n+    res = next(ar.drop_(testfile))\r\n     eq_(res['command'], 'drop')\r\n     eq_(res['success'], False)\r\n     assert_in('adjust numcopies', res['note'])\r\n@@ -1371,7 +1371,8 @@ def test_annex_drop(src, dst):\r\n     eq_(len([f for f in ar.fsck(fast=True) if f['file'] == testfile]), 1)\r\n \r\n     # drop file by name:\r\n-    result = ar.drop([testfile])\r\n+    # use generator version so it doesn't raise even if fails\r\n+    result = list(ar.drop_(testfile))\r\n     assert_false(ar.file_has_content(testfile))\r\n     ok_(isinstance(result, list))\r\n     eq_(len(result), 1)\r\n@@ -1383,7 +1384,7 @@ def test_annex_drop(src, dst):\r\n \r\n     # drop file by key:\r\n     testkey = ar.get_file_key(testfile)\r\n-    result = ar.drop([testkey], key=True)\r\n+    result = list(ar.drop_(testkey, key=True))\r\n     assert_false(ar.file_has_content(testfile))\r\n     ok_(isinstance(result, list))\r\n     eq_(len(result), 1)\r\n```\r\n</details>", "closed_by": {"login": "mih", "id": 136479, "node_id": "MDQ6VXNlcjEzNjQ3OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/136479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mih", "html_url": "https://github.com/mih", "followers_url": "https://api.github.com/users/mih/followers", "following_url": "https://api.github.com/users/mih/following{/other_user}", "gists_url": "https://api.github.com/users/mih/gists{/gist_id}", "starred_url": "https://api.github.com/users/mih/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mih/subscriptions", "organizations_url": "https://api.github.com/users/mih/orgs", "repos_url": "https://api.github.com/users/mih/repos", "events_url": "https://api.github.com/users/mih/events{/privacy}", "received_events_url": "https://api.github.com/users/mih/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/5048/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/5048/timeline", "performed_via_github_app": null}