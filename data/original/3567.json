{"url": "https://api.github.com/repos/datalad/datalad/issues/3567", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/3567/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/3567/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/3567/events", "html_url": "https://github.com/datalad/datalad/issues/3567", "id": 474224196, "node_id": "MDU6SXNzdWU0NzQyMjQxOTY=", "number": 3567, "title": "seems we need to optimize get (may be others) results rendering (?) to avoid a heavy loop of resolving subdatasets", "user": {"login": "yarikoptic", "id": 39889, "node_id": "MDQ6VXNlcjM5ODg5", "avatar_url": "https://avatars.githubusercontent.com/u/39889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yarikoptic", "html_url": "https://github.com/yarikoptic", "followers_url": "https://api.github.com/users/yarikoptic/followers", "following_url": "https://api.github.com/users/yarikoptic/following{/other_user}", "gists_url": "https://api.github.com/users/yarikoptic/gists{/gist_id}", "starred_url": "https://api.github.com/users/yarikoptic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yarikoptic/subscriptions", "organizations_url": "https://api.github.com/users/yarikoptic/orgs", "repos_url": "https://api.github.com/users/yarikoptic/repos", "events_url": "https://api.github.com/users/yarikoptic/events{/privacy}", "received_events_url": "https://api.github.com/users/yarikoptic/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2019-07-29T19:45:50Z", "updated_at": "2020-03-24T10:54:35Z", "closed_at": "2020-03-24T10:54:35Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "Manifests on 0.11.x (log messages are different but feels the same) and master (0.12.0rc4-267-g5e410c26).  \r\n`datalad run` with a good number of (globbed) inputs (>1000) from subdatasets resulted in an hour or so of waiting to get pass the message `Making sure inputs are available (this may take some time)`. I interrupted it since it was not clear if it would complete in any (un)reasonable time.\r\n\r\nWith the \"generators all the way down\" I thought that backtrace is useless and that the actual \"useful action\" is somewhere else, but I think what I have observed (shown below) is indeed just a \"results rendering\" loop!\r\n\r\n```\r\n...\r\n  /home/XXX/proj/datalad/datalad-master/datalad/interface/utils.py(520)_process_results()\r\n-> for res in results:\r\n  /home/XXX/proj/datalad/datalad-master/datalad/distribution/get.py(470)__call__()\r\n-> on_failure='ignore'):\r\n  /home/XXX/proj/datalad/datalad-master/datalad/interface/utils.py(428)generator_func()\r\n-> result_renderer, result_xfm, _result_filter, **_kwargs):\r\n  /home/XXX/proj/datalad/datalad-master/datalad/interface/utils.py(520)_process_results()\r\n-> for res in results:\r\n  /home/XXX/proj/datalad/datalad-master/datalad/interface/annotate_paths.py(679)__call__()\r\n-> result_xfm=None, result_filter=None, return_type='list')\r\n  /data/R03/WM-R03/venvs/master/lib/python3.5/site-packages/wrapt/wrappers.py(603)__call__()\r\n-> args, kwargs)\r\n  /home/XXX/proj/datalad/datalad-master/datalad/distribution/dataset.py(525)apply_func()\r\n-> return f(**kwargs)\r\n  /data/R03/WM-R03/venvs/master/lib/python3.5/site-packages/wrapt/wrappers.py(564)__call__()\r\n-> args, kwargs)\r\n  /home/XXX/proj/datalad/datalad-master/datalad/interface/utils.py(491)eval_func()\r\n-> return return_func(generator_func)(*args, **kwargs)\r\n  /data/R03/WM-R03/venvs/master/lib/python3.5/site-packages/wrapt/wrappers.py(564)__call__()\r\n-> args, kwargs)\r\n  /home/XXX/proj/datalad/datalad-master/datalad/interface/utils.py(479)return_func()\r\n-> results = list(results)\r\n  /home/XXX/proj/datalad/datalad-master/datalad/interface/utils.py(428)generator_func()\r\n-> result_renderer, result_xfm, _result_filter, **_kwargs):\r\n  /home/XXX/proj/datalad/datalad-master/datalad/interface/utils.py(520)_process_results()\r\n-> for res in results:\r\n> /home/XXX/proj/datalad/datalad-master/datalad/local/subdatasets.py(282)__call__()\r\n-> ds = require_dataset(\r\n```\r\n\r\nand here is the tip of the very long loop leading to all those log messages:\r\n```\r\n[DEBUG  ] Resolved dataset for subdataset reporting/modification: <Dataset path=/data/R03/WM-R03/analyses/1st-level> \r\n[DEBUG  ] Query subdatasets of <Dataset path=/data/R03/WM-R03/analyses/1st-level> \r\n```\r\nwhich were repeated probably for thousands of times upon initial `-l debug` rerun, which was interrupted after awhile.  Not yet 100% sure if that was the original culprit but IMHO sounds like something which could/should be avoided anyways:\r\n```\r\n[DEBUG  ] Resolved dataset for subdataset reporting/modification: <Dataset path=/data/R03/WM-R03/analyses> \r\n[DEBUG  ] Query subdatasets of <Dataset path=/data/R03/WM-R03/analyses> \r\n[DEBUG  ] <AnnexRepo path=/data/R03/WM-R03/analyses (<class 'datalad.support.annexrepo.AnnexRepo'>)>.get_content_info(...) \r\n[DEBUG  ] Query repo: ['git', 'ls-files', '--stage', '-z', '-d', '-m', '--exclude-standard'] \r\n[DEBUG  ] Done query repo: ['git', 'ls-files', '--stage', '-z', '-d', '-m', '--exclude-standard'] \r\n[DEBUG  ] Done <AnnexRepo path=/data/R03/WM-R03/analyses (<class 'datalad.support.annexrepo.AnnexRepo'>)>.get_content_info(...) \r\n[DEBUG  ] already installed [get(/data/R03/WM-R03/analyses/1st-level)] \r\n[DEBUG  ] chdir '/data/R03/WM-R03/analyses' -> '/data/R03/WM-R03/analyses'  \r\n[DEBUG  ] chdir '/data/R03/WM-R03/analyses' -> '/data/R03/WM-R03/analyses' (coming back) \r\n[DEBUG  ] Determined class of decorated function: <class 'datalad.distribution.get.Get'> \r\n[DEBUG  ] Determined class of decorated function: <class 'datalad.interface.annotate_paths.AnnotatePaths'> \r\n[DEBUG  ] Determined class of decorated function: <class 'datalad.local.subdatasets.Subdatasets'> \r\n> /home/XXX/proj/datalad/datalad-master/datalad/local/subdatasets.py(282)__call__()\r\n-> ds = require_dataset(\r\n(Pdb) c\r\n[DEBUG  ] Resolved dataset for subdataset reporting/modification: <Dataset path=/data/R03/WM-R03/analyses/1st-level> \r\n[DEBUG  ] Query subdatasets of <Dataset path=/data/R03/WM-R03/analyses/1st-level> \r\n[DEBUG  ] Determined class of decorated function: <class 'datalad.local.subdatasets.Subdatasets'> \r\n> /home/XXX/proj/datalad/datalad-master/datalad/local/subdatasets.py(282)__call__()\r\n-> ds = require_dataset(\r\n(Pdb) c\r\n[DEBUG  ] Resolved dataset for subdataset reporting/modification: <Dataset path=/data/R03/WM-R03/analyses/1st-level> \r\n[DEBUG  ] Query subdatasets of <Dataset path=/data/R03/WM-R03/analyses/1st-level> \r\n[DEBUG  ] Determined class of decorated function: <class 'datalad.local.subdatasets.Subdatasets'> \r\n> /home/XXX/proj/datalad/datalad-master/datalad/local/subdatasets.py(282)__call__()\r\n-> ds = require_dataset(\r\n```\r\n\r\nThe invocation was \r\n```shell\r\n$ datalad -l debug run -m \"Running all 2nd level (subj mean) analyses\" --input '1st-level/*.feat' --output '1st-level/*/reg_standard' --output '1st-level/*/*log.html' --output '2nd-level/*.gfeat' bash -c 'for f in 2nd-level/*.fsf; do ff=${{f/.fsf/.feat}}; [ -e $ff ] || echo $f; done| xargs parallel -j 12 ../.datalad/environments/fslanal/run feat -- '\r\n```\r\nwhere `1st-level` and `2nd-level` are subdatasets.\r\n\r\nI thought that it is just a matter of paths to get coming out from subdatasets, but it seems to be not the case since on a simplified example for that it doesn't happen (ran `datalad create /tmp/testds && cd /tmp/testds && datalad install -d . ///openfmri/ds000001  ///openfmri/ds000002 && datalad -l debug get */*/func/sub-*events*tsv `).", "closed_by": {"login": "mih", "id": 136479, "node_id": "MDQ6VXNlcjEzNjQ3OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/136479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mih", "html_url": "https://github.com/mih", "followers_url": "https://api.github.com/users/mih/followers", "following_url": "https://api.github.com/users/mih/following{/other_user}", "gists_url": "https://api.github.com/users/mih/gists{/gist_id}", "starred_url": "https://api.github.com/users/mih/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mih/subscriptions", "organizations_url": "https://api.github.com/users/mih/orgs", "repos_url": "https://api.github.com/users/mih/repos", "events_url": "https://api.github.com/users/mih/events{/privacy}", "received_events_url": "https://api.github.com/users/mih/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/3567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/3567/timeline", "performed_via_github_app": null}