{"url": "https://api.github.com/repos/datalad/datalad/issues/3521", "repository_url": "https://api.github.com/repos/datalad/datalad", "labels_url": "https://api.github.com/repos/datalad/datalad/issues/3521/labels{/name}", "comments_url": "https://api.github.com/repos/datalad/datalad/issues/3521/comments", "events_url": "https://api.github.com/repos/datalad/datalad/issues/3521/events", "html_url": "https://github.com/datalad/datalad/issues/3521", "id": 466176814, "node_id": "MDU6SXNzdWU0NjYxNzY4MTQ=", "number": 3521, "title": "Feature-request: IO-limiting mode for `get` operations", "user": {"login": "mih", "id": 136479, "node_id": "MDQ6VXNlcjEzNjQ3OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/136479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mih", "html_url": "https://github.com/mih", "followers_url": "https://api.github.com/users/mih/followers", "following_url": "https://api.github.com/users/mih/following{/other_user}", "gists_url": "https://api.github.com/users/mih/gists{/gist_id}", "starred_url": "https://api.github.com/users/mih/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mih/subscriptions", "organizations_url": "https://api.github.com/users/mih/orgs", "repos_url": "https://api.github.com/users/mih/repos", "events_url": "https://api.github.com/users/mih/events{/privacy}", "received_events_url": "https://api.github.com/users/mih/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 736433505, "node_id": "MDU6TGFiZWw3MzY0MzM1MDU=", "url": "https://api.github.com/repos/datalad/datalad/labels/severity-wishlist", "name": "severity-wishlist", "color": "ffeeee", "default": false, "description": "feature request, or bugs that are very difficult to fix due to design issues"}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-07-10T08:37:31Z", "updated_at": "2019-07-15T13:39:53Z", "closed_at": "2019-07-15T13:39:53Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "## Scenario\r\n\r\nThere is a dataset with a few (<30) files that are each huge (each is several dozen GB of https://www.awaresystems.be/imaging/tiff/bigtiff.html). The \"normal\" procedure to capture the (comparatively) small results of an analysis of these data is to\r\n\r\n- create a new dataset for the results\r\n- install the bigtiff dataset as a subdataset\r\n- use `datalad run` with appropriate `--input` args to execute the analysis\r\n\r\n## Problem\r\n\r\nThis procedure creates a substantial IO bottleneck. Even if all IO is happening locally on a machine (shared file system), about 1 *TB* of data needs to be copied -- which takes time, a sizable chunk of additional storage, and causes noticeable churn on the filesystem. In this scenario, this copy has a lifetime of only a few minutes (the run time of the analysis). Afterwards, it will be thrown away.\r\n\r\n## Potential solutions\r\n\r\nWe already have `install --reckless` that was motivated by a similar desire (fast read-only access, previous discussion https://github.com/datalad/datalad/issues/1):\r\n\r\n```\r\n  --reckless      Set up the dataset to be able to obtain content in the\r\n                        cheapest/fastest possible way, even if this poses a\r\n                        potential risk to data integrity (e.g. hardlink files\r\n                        from a local clone of the dataset). Use with care, and\r\n                        limit to \"read-only\" use cases. With this flag the\r\n                        installed dataset will be marked as untrusted.\r\n                        [Default: False]\r\n```\r\n\r\nwhich ultimately sets `annex.hardlink=true` and `untrust`s that clone. This can help if the data is on the same filesystem, but is helpless if not. In the concrete case that motivates this issue, we are on HPC infrastructure, and the input data lives on a dedicated filesystem (GPFS) that is providing relatively static data to an army of compute nodes.\r\n\r\nWhat about populating `.git/annex/objects` of the temporary input dataset clone with **symlinks** to the keys in `.git/annex/objects` of the source dataset on the other file system? This would constrain storage impact to the number of inodes, but have little to no cost re size and bandwidth.\r\nOr even have `.git/annex/objects` itself be a straight-up symlink to the entire annex tree of the source dataset? In that case, we could even save a (possibly substantial) number of required inodes on the FS (not much of an issue in this concrete scenario, but a general concern with many HPC setups). Of course, this is only meaningful for read-only operations (and writes could be prevented by appropriate permission constraints on the source dataset directories).\r\n\r\n@bpoldrack will shortly report on an exploration on how git-annex reacts to such a setup. \r\n\r\n@joeyh it would be great to get your thoughts on this approach for a cheap, temporary, read-only access.", "closed_by": {"login": "kyleam", "id": 1297788, "node_id": "MDQ6VXNlcjEyOTc3ODg=", "avatar_url": "https://avatars.githubusercontent.com/u/1297788?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kyleam", "html_url": "https://github.com/kyleam", "followers_url": "https://api.github.com/users/kyleam/followers", "following_url": "https://api.github.com/users/kyleam/following{/other_user}", "gists_url": "https://api.github.com/users/kyleam/gists{/gist_id}", "starred_url": "https://api.github.com/users/kyleam/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kyleam/subscriptions", "organizations_url": "https://api.github.com/users/kyleam/orgs", "repos_url": "https://api.github.com/users/kyleam/repos", "events_url": "https://api.github.com/users/kyleam/events{/privacy}", "received_events_url": "https://api.github.com/users/kyleam/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/datalad/datalad/issues/3521/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/datalad/datalad/issues/3521/timeline", "performed_via_github_app": null}